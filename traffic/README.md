For the load data function, I first tried to cv2.resize each image to the correct size and use it as a buffer in an np.ndarray. This didn't work, so I further looked into cv2 and numpy. Thus, I found out cv2.imread which automatically formats the image into a np.ndarray. I used to imread and resize to format the image into a ndarray. There was a problem, however, which was that I tried to access the images through a for loop that loops through all elements of os.listdir(data_dir[i]), not realising that datadir[i] just gives the char at the position i of the string that is the name of the directory and doesn't give the paths to the images. Therefore, I added two more lines to determine the file path to each category and to each image, through os.path.join, and used the image path as an input to the imread function. I then tested this by printing the shape of the formatted images which proved to be successfull by outputting (30, 30, 3).

For the get model function, I used the handwriting example from the lecture and removed or changed certain values to build the basic layers of my convolutional neural network. Removing the flatten statement caused a Value Error saying the shapes are not compatible. To understand what is happening I used the model.summary() function and recognized the necessity of the flatten statement when transitioning from inputted images to units in a neural network. My first models accuracy was 5%, so I added more convolutional and pooling layers and incresed the number of units in my hidden layer which increase my accuracy to 55% percent which I was satisfied with.
